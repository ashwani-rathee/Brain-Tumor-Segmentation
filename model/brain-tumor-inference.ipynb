{"cells":[{"cell_type":"markdown","metadata":{},"source":["This is how we can get the inference results from the trained model i.e. inference_file.pt . It might not work directly without some tinkering in file paths. I did these inference testings on kaggle. And in the rest api, a lot of the code is shaved off to declutter and make it very fast(6 secs for a inference)."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:38:16.894077Z","iopub.status.busy":"2021-10-15T07:38:16.893755Z","iopub.status.idle":"2021-10-15T07:38:25.394714Z","shell.execute_reply":"2021-10-15T07:38:25.393863Z","shell.execute_reply.started":"2021-10-15T07:38:16.893985Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchsummary\n","  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n","Installing collected packages: torchsummary\n","Successfully installed torchsummary-1.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:38:25.397058Z","iopub.status.busy":"2021-10-15T07:38:25.396788Z","iopub.status.idle":"2021-10-15T07:38:27.384459Z","shell.execute_reply":"2021-10-15T07:38:27.383754Z","shell.execute_reply.started":"2021-10-15T07:38:25.397024Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","%matplotlib inline\n","import random\n","import warnings\n","import pickle\n","warnings.filterwarnings('ignore')\n","from tensorboardX import SummaryWriter\n","\n","from datetime import datetime\n","from time import time\n","\n","import torch\n","from torch.utils.data import SubsetRandomSampler\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:38:27.386275Z","iopub.status.busy":"2021-10-15T07:38:27.385985Z","iopub.status.idle":"2021-10-15T07:38:27.415095Z","shell.execute_reply":"2021-10-15T07:38:27.414229Z","shell.execute_reply.started":"2021-10-15T07:38:27.386238Z"},"trusted":true},"outputs":[],"source":["class DynamicUNet(nn.Module):\n","    def __init__(self, filters, input_channels=1, output_channels=1):\n","        super(DynamicUNet, self).__init__()\n","\n","        if len(filters) != 5:\n","            raise Exception(f\"Filter list size {len(filters)}, expected 5!\")\n","\n","        padding = 1\n","        ks = 3\n","        # Encoding Part of Network.\n","        #   Block 1\n","        self.conv1_1 = nn.Conv2d(input_channels, filters[0], kernel_size=ks, padding=padding)\n","        self.conv1_2 = nn.Conv2d(filters[0], filters[0], kernel_size=ks, padding=padding)\n","        self.maxpool1 = nn.MaxPool2d(2)\n","        #   Block 2\n","        self.conv2_1 = nn.Conv2d(filters[0], filters[1], kernel_size=ks, padding=padding)\n","        self.conv2_2 = nn.Conv2d(filters[1], filters[1], kernel_size=ks, padding=padding)\n","        self.maxpool2 = nn.MaxPool2d(2)\n","        #   Block 3\n","        self.conv3_1 = nn.Conv2d(filters[1], filters[2], kernel_size=ks, padding=padding)\n","        self.conv3_2 = nn.Conv2d(filters[2], filters[2], kernel_size=ks, padding=padding)\n","        self.maxpool3 = nn.MaxPool2d(2)\n","        #   Block 4\n","        self.conv4_1 = nn.Conv2d(filters[2], filters[3], kernel_size=ks, padding=padding)\n","        self.conv4_2 = nn.Conv2d(filters[3], filters[3], kernel_size=ks, padding=padding)\n","        self.maxpool4 = nn.MaxPool2d(2)\n","        \n","        # Bottleneck Part of Network.\n","        self.conv5_1 = nn.Conv2d(filters[3], filters[4], kernel_size=ks, padding=padding)\n","        self.conv5_2 = nn.Conv2d(filters[4], filters[4], kernel_size=ks, padding=padding)\n","        self.conv5_t = nn.ConvTranspose2d(filters[4], filters[3], 2, stride=2)\n","\n","        # Decoding Part of Network.\n","        #   Block 4\n","        self.conv6_1 = nn.Conv2d(filters[4], filters[3], kernel_size=ks, padding=padding)\n","        self.conv6_2 = nn.Conv2d(filters[3], filters[3], kernel_size=ks, padding=padding)\n","        self.conv6_t = nn.ConvTranspose2d(filters[3], filters[2], 2, stride=2)\n","        #   Block 3\n","        self.conv7_1 = nn.Conv2d(filters[3], filters[2], kernel_size=ks, padding=padding)\n","        self.conv7_2 = nn.Conv2d(filters[2], filters[2], kernel_size=ks, padding=padding)\n","        self.conv7_t = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n","        #   Block 2\n","        self.conv8_1 = nn.Conv2d(filters[2], filters[1], kernel_size=ks, padding=padding)\n","        self.conv8_2 = nn.Conv2d(filters[1], filters[1], kernel_size=ks, padding=padding)\n","        self.conv8_t = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n","        #   Block 1\n","        self.conv9_1 = nn.Conv2d(filters[1], filters[0], kernel_size=ks, padding=padding)\n","        self.conv9_2 = nn.Conv2d(filters[0], filters[0], kernel_size=ks, padding=padding)\n","\n","        # Output Part of Network.\n","        self.conv10 = nn.Conv2d(filters[0], output_channels, kernel_size=ks, padding=padding)\n","\n","    def forward(self, x):\n","\n","        # Encoding Part of Network.\n","        #   Block 1\n","        conv1 = F.relu(self.conv1_1(x))\n","        conv1 = F.relu(self.conv1_2(conv1))\n","        pool1 = self.maxpool1(conv1)\n","        #   Block 2\n","        conv2 = F.relu(self.conv2_1(pool1))\n","        conv2 = F.relu(self.conv2_2(conv2))\n","        pool2 = self.maxpool2(conv2)\n","        #   Block 3\n","        conv3 = F.relu(self.conv3_1(pool2))\n","        conv3 = F.relu(self.conv3_2(conv3))\n","        pool3 = self.maxpool3(conv3)\n","        #   Block 4\n","        conv4 = F.relu(self.conv4_1(pool3))\n","        conv4 = F.relu(self.conv4_2(conv4))\n","        pool4 = self.maxpool4(conv4)\n","\n","        # Bottleneck Part of Network.\n","        conv5 = F.relu(self.conv5_1(pool4))\n","        conv5 = F.relu(self.conv5_2(conv5))\n","\n","        # Decoding Part of Network.\n","        #   Block 4\n","        up6 = torch.cat((self.conv5_t(conv5), conv4), dim=1)\n","        conv6 = F.relu(self.conv6_1(up6))\n","        conv6 = F.relu(self.conv6_2(conv6))\n","        #   Block 3\n","        up7 = torch.cat((self.conv6_t(conv6), conv3), dim=1)\n","        conv7 = F.relu(self.conv7_1(up7))\n","        conv7 = F.relu(self.conv7_2(conv7))\n","        #   Block 2\n","        up8 = torch.cat((self.conv7_t(conv7), conv2), dim=1)\n","        conv8 = F.relu(self.conv8_1(up8))\n","        conv8 = F.relu(self.conv8_2(conv8))\n","        #   Block 1\n","        up9 = torch.cat((self.conv8_t(conv8), conv1), dim=1)\n","        conv9 = F.relu(self.conv9_1(up9))\n","        conv9 = F.relu(self.conv9_2(conv9))\n","\n","        # Output Part of Network.\n","        output = F.sigmoid(self.conv10(conv9))\n","\n","        return output\n","\n","    def summary(self, input_size=(1, 512, 512), batch_size=-1, device='cuda'):\n","        return summary(self, input_size, batch_size, device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:39:01.023554Z","iopub.status.busy":"2021-10-15T07:39:01.023245Z","iopub.status.idle":"2021-10-15T07:39:01.035356Z","shell.execute_reply":"2021-10-15T07:39:01.034629Z","shell.execute_reply.started":"2021-10-15T07:39:01.023524Z"},"trusted":true},"outputs":[],"source":["class DiceLoss(nn.Module):\n","    def __init__(self):\n","        \"\"\"Simple constructor for the class.\"\"\"\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, predicted, target):\n","        batch = predicted.size()[0]\n","        batch_loss = 0\n","        for index in range(batch):\n","            coefficient = self._dice_coefficient(\n","                predicted[index], target[index])\n","            batch_loss += coefficient\n","\n","        batch_loss = batch_loss / batch\n","\n","        return 1 - batch_loss\n","\n","    def _dice_coefficient(self, predicted, target):\n","        smooth = 1\n","        product = torch.mul(predicted, target)\n","        intersection = product.sum()\n","        coefficient = (2*intersection + smooth) / \\\n","            (predicted.sum() + target.sum() + smooth)\n","        return coefficient\n","\n","\n","class BCEDiceLoss(nn.Module):\n","    def __init__(self, device):\n","        \"\"\"Simple constructor for the class.\"\"\"\n","        super(BCEDiceLoss, self).__init__()\n","        self.dice_loss = DiceLoss().to(device)\n","\n","    def forward(self, predicted, target):\n","        \"\"\" Method for calculation of combined loss from sample.\"\"\"\n","        return F.binary_cross_entropy(predicted, target) \\\n","            + self.dice_loss(predicted, target)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:39:01.565292Z","iopub.status.busy":"2021-10-15T07:39:01.565054Z","iopub.status.idle":"2021-10-15T07:39:01.596135Z","shell.execute_reply":"2021-10-15T07:39:01.595478Z","shell.execute_reply.started":"2021-10-15T07:39:01.565265Z"},"trusted":true},"outputs":[],"source":["class BrainTumorClassifier():\n","    def __init__(self, model, device):\n","        self.model = model\n","        self.device = device\n","        self.criterion = BCEDiceLoss(self.device).to(device)\n","        self.log_path = datetime.now().strftime(\"%I-%M-%S_%p_on_%B_%d,_%Y\")\n","\n","    def train(self, epochs, trainloader, mini_batch=None, learning_rate=0.001, save_best=None, plot_image=None):\n","        # Tensorboard Writter\n","        self.tb_writer = SummaryWriter(log_dir=f'logs/{self.log_path}')\n","        # Training session history data.\n","        history = {'train_loss': list()}\n","        # For save best feature. Initial loss taken a very high value.\n","        last_loss = 1000\n","        # Optimizer used for training process. Adam Optimizer.\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n","        # Reducing LR on plateau feature to improve training.\n","        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            self.optimizer, factor=0.85, patience=2, verbose=True)\n","        print('Starting Training Process')\n","        # Epoch Loop\n","        for epoch in range(epochs):\n","            start_time = time()\n","            # Training a single epoch\n","            epoch_loss = self._train_epoch(trainloader, mini_batch)\n","            # Collecting all epoch loss values for future visualization.\n","            history['train_loss'].append(epoch_loss)\n","            # Logging to Tensorboard\n","            self.tb_writer.add_scalar('Train Loss', epoch_loss, epoch)\n","            self.tb_writer.add_scalar(\n","                'Learning Rate', self.optimizer.param_groups[0]['lr'], epoch)\n","            # Reduce LR On Plateau\n","            self.scheduler.step(epoch_loss)\n","\n","            # Plotting some sample output on TensorBoard for visualization purpose.\n","            if plot_image:\n","                self.model.eval()\n","                self._plot_image(epoch, plot_image)\n","                self.model.train()\n","\n","            time_taken = time()-start_time\n","            # Training Logs printed.\n","            print(f'Epoch: {epoch+1:03d},  ', end='')\n","            print(f'Loss:{epoch_loss:.7f},  ', end='')\n","            print(f'Time:{time_taken:.2f}secs', end='')\n","\n","            # Save the best model with lowest epoch loss feature.\n","            if save_best != None and last_loss > epoch_loss:\n","                self.save_model(save_best)\n","                last_loss = epoch_loss\n","                print(f'\\tSaved at loss: {epoch_loss:.10f}')\n","            else:\n","                print()\n","        return history\n","\n","    def save_model(self, path):\n","        torch.save(self.model.state_dict(), path)\n","\n","    def restore_model(self, path):\n","        if self.device == 'cpu':\n","            self.model.load_state_dict(torch.load(path, map_location=device))\n","        else:\n","            self.model.load_state_dict(torch.load(path))\n","            self.model.to(self.device)\n","\n","    def test(self, testloader, threshold=0.5):\n","        # Putting the model to evaluation mode\n","        self.model.eval()\n","        # Getting test data indices for dataloading\n","        test_data_indexes = testloader.sampler.indices[:]\n","        # Total testing data used.\n","        data_len = len(test_data_indexes)\n","        # Score after testing on dataset.\n","        mean_val_score = 0\n","\n","        # Error checking to set testloader batch size to 1.\n","        batch_size = testloader.batch_size\n","        if batch_size != 1:\n","            raise Exception(\"Set batch size to 1 for testing purpose\")\n","        # Converting to iterator to get data in loops.\n","        testloader = iter(testloader)\n","        # Running the loop until no more data is left to test.\n","        while len(test_data_indexes) != 0:\n","            # Getting a data sample.\n","            data = testloader.next()\n","            # Getting the data index\n","            index = int(data['index'])\n","            # Removing the data index from total data indices\n","            # to indicate this data score has been included.\n","            if index in test_data_indexes:\n","                test_data_indexes.remove(index)\n","            else:\n","                continue\n","            # Data prepared to be given as input to model.\n","            image = data['image'].view((1, 1, 512, 512)).to(self.device)\n","            mask = data['mask']\n","\n","            # Predicted output from the input sample.\n","            mask_pred = self.model(image).cpu()\n","            # Threshold elimination.\n","            mask_pred = (mask_pred > threshold)\n","            mask_pred = mask_pred.numpy()\n","            \n","            mask = np.resize(mask, (1, 512, 512))\n","            mask_pred = np.resize(mask_pred, (1, 512, 512))\n","            \n","            # Calculating the dice score for original and \n","            # constructed image mask.\n","            mean_val_score += self._dice_coefficient(mask_pred, mask)\n","\n","        # Calculating the mean score for the whole test dataset.\n","        mean_val_score = mean_val_score / data_len\n","        # Putting the model back to training mode.\n","        self.model.train()\n","        return mean_val_score\n","\n","    def predict(self, data, threshold=0.5):\n","        self.model.eval()\n","        image = data['image'].numpy()\n","        mask = data['mask'].numpy()\n","\n","        image_tensor = torch.Tensor(data['image'])\n","        image_tensor = image_tensor.view((-1, 1, 512, 512)).to(self.device)\n","        output = self.model(image_tensor).detach().cpu()\n","        output = (output > threshold)\n","        output = output.numpy()\n","\n","        image = np.resize(image, (512, 512))\n","        mask = np.resize(mask, (512, 512))\n","        output = np.resize(output, (512, 512))\n","        score = self._dice_coefficient(output, mask)\n","        return image, mask, output, score\n","\n","    def _train_epoch(self, trainloader, mini_batch):\n","        epoch_loss, batch_loss, batch_iteration = 0, 0, 0\n","        for batch, data in enumerate(trainloader):\n","            # Keeping track how many iteration is happening.\n","            batch_iteration += 1\n","            # Loading data to device used.\n","            image = data['image'].to(self.device)\n","            mask = data['mask'].to(self.device)\n","            # Clearing gradients of optimizer.\n","            self.optimizer.zero_grad()\n","            # Calculation predicted output using forward pass.\n","            output = self.model(image)\n","            # Calculating the loss value.\n","            loss_value = self.criterion(output, mask)\n","            # Computing the gradients.\n","            loss_value.backward()\n","            # Optimizing the network parameters.\n","            self.optimizer.step()\n","            # Updating the running training loss\n","            epoch_loss += loss_value.item()\n","            batch_loss += loss_value.item()\n","\n","            # Printing batch logs if any.\n","            if mini_batch:\n","                if (batch+1) % mini_batch == 0:\n","                    batch_loss = batch_loss / \\\n","                        (mini_batch*trainloader.batch_size)\n","                    print(\n","                        f'    Batch: {batch+1:02d},\\tBatch Loss: {batch_loss:.7f}')\n","                    batch_loss = 0\n","\n","        epoch_loss = epoch_loss/(batch_iteration*trainloader.batch_size)\n","        return epoch_loss\n","\n","    def _plot_image(self, epoch, sample):\n","        inputs = list()\n","        mask = list()\n","\n","        # Inputs seperated.\n","        for data in sample:\n","            inputs.append(data['image'])\n","        # Inputs stacked together in a single batch\n","        inputs = torch.stack(inputs).to(self.device)\n","        # Outputs gained from model after passing input.\n","        outputs = self.model(inputs).detach().cpu()\n","        # Adding the outputs to Tensorboard for visualization.\n","        for index in range(len(sample)):\n","            self.tb_writer.add_image(\n","                str(sample[index]['index']), outputs[index], epoch)\n","        # Deleting the samples from GPU memory to save space.\n","        del inputs\n","\n","    def _dice_coefficient(self, predicted, target):\n","        smooth = 1\n","        product = np.multiply(predicted, target)\n","        intersection = np.sum(product)\n","        coefficient = (2*intersection + smooth) / \\\n","            (np.sum(predicted) + np.sum(target) + smooth)\n","        return coefficient"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T07:57:57.298233Z","iopub.status.busy":"2021-10-15T07:57:57.297961Z","iopub.status.idle":"2021-10-15T07:57:57.343795Z","shell.execute_reply":"2021-10-15T07:57:57.342870Z","shell.execute_reply.started":"2021-10-15T07:57:57.298203Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Computation Details\n","\tDevice Used: (cuda)  Tesla P100-PCIE-16GB\n","\n","Packages Used Versions:-\n","\tPytorch Version: 1.9.1\n","Saved model loaded\n"]}],"source":["unet_model = None\n","unet_classifier = None\n","# Filters used in UNet Model\n","FILTER_LIST = [16,32,64,128,256]\n","MODEL_NAME = f\"brain_tumor_segmentor.pt\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print('Computation Details')\n","print(f'\\tDevice Used: ({device})  {torch.cuda.get_device_name(torch.cuda.current_device())}\\n')\n","\n","print('Packages Used Versions:-')\n","print(f'\\tPytorch Version: {torch.__version__}')\n","# Saved model is loaded on memory.\n","unet_model = DynamicUNet(FILTER_LIST)\n","unet_classifier = BrainTumorClassifier(unet_model,device)\n","unet_classifier.restore_model(os.path.join('../input/bts-segmenter',MODEL_NAME))\n","print('Saved model loaded')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T08:03:02.157555Z","iopub.status.busy":"2021-10-15T08:03:02.157279Z","iopub.status.idle":"2021-10-15T08:03:07.291077Z","shell.execute_reply":"2021-10-15T08:03:07.290297Z","shell.execute_reply.started":"2021-10-15T08:03:02.157523Z"},"trusted":true},"outputs":[],"source":["sample = {\"image\":TF.to_tensor(io.imread('https://i.imgur.com/MWC4ywP.png')),\"mask\":TF.to_tensor(io.imread('https://i.imgur.com/8g42o7T.png') )}\n","# sample\n","image, mask, output, d_score = unet_classifier.predict(sample,0.65)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2021-10-15T08:16:12.764409Z","iopub.status.busy":"2021-10-15T08:16:12.764137Z","iopub.status.idle":"2021-10-15T08:16:12.968237Z","shell.execute_reply":"2021-10-15T08:16:12.967481Z","shell.execute_reply.started":"2021-10-15T08:16:12.764379Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from skimage import data, io\n","from matplotlib import pyplot as plt\n","io.imshow(output)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
